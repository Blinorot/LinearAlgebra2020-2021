\ProvidesFile{lecture07.tex}[Лекция 7]


\begin{claim}
[Мультипликативность определителя]\label{claim::DetMulti}
Пусть $A,B\in\Matrix{n}$ -- произвольные матрицы.
Тогда $\det(AB) = \det(A)\det(B)$.
\end{claim}
\begin{proof}
Фиксируем матрицу $B\in\Matrix{n}$ и рассмотрим отображение $\gamma\colon \Matrix{n}\to \mathbb R$ по правилу $A\mapsto \det(AB)$.
Если $A_1,\ldots, A_n$ -- строки матрицы $A$, то $A_1B, \ldots, A_nB$ -- строки матрицы $AB$.
Из этого легко видеть, что $\gamma$ -- полилинейна и кососимметрическая функция по строкам матрицы $A$.
Значит по утверждению~\ref{claim::PolyAntiUnique} $\gamma(A) = \det(A)\gamma(E)$.
Но последнее равносильно $\det(AB) = \det(A)\det (B)$.
\end{proof}

\begin{claim}
[Определитель с углом нулей]
Пусть $A,\in\Matrix{n}$ и $B\in\Matrix{m}$.
Тогда
\[
\det
\begin{pmatrix}
{A}&{*}\\
{0}&{B}
\end{pmatrix}
=
\det
\begin{pmatrix}
{A}&{0}\\
{*}&{B}
\end{pmatrix}
=
\det(A) \det(B)
\]
\end{claim}
\begin{proof}
Рассмотрим функцию $\phi\colon \Matrix{n}\to \mathbb R$ по правилу
\[
\phi(X) = 
\det
\begin{pmatrix}
{X}&{*}\\
{0}&{B}
\end{pmatrix}
\]
Заметим, что эта функция является полилинейной и кососимметричной по столбцам матрицы $X$.
В этом случае по утверждению~\ref{claim::PolyAntiUnique} о единственности для полилинейных кососимметрических отображений она имеет вид $\phi(X) = \det(X)\phi(E)$, то есть
\[
\det
\begin{pmatrix}
{A}&{*}\\
{0}&{B}
\end{pmatrix}
=
\det A
\det
\begin{pmatrix}
{E}&{*}\\
{0}&{B}
\end{pmatrix}
\]
Теперь рассмотрим функцию $\psi\colon \Matrix{m}\to \mathbb R$ по правилу
\[
\psi(X) =
\det
\begin{pmatrix}
{E}&{*}\\
{0}&{X}
\end{pmatrix}
\]
Заметим, что эта функция является полилинейной и кососимметричной по строкам матрицы $X$.
В этом случае по утверждению~\ref{claim::PolyAntiUnique} о единственности для полилинейных кососимметрических отображений она имеет вид $\psi(X) = \det(X)\psi(E)$, то есть
\[
\det
\begin{pmatrix}
{E}&{*}\\
{0}&{B}
\end{pmatrix}
=
\det B
\det
\begin{pmatrix}
{E}&{*}\\
{0}&{E}
\end{pmatrix}
\]
Последний определитель равен $1$, так как по утверждению~\ref{claim::DetUpperTr} определитель верхнетреугольной матрицы равен произведению ее диагональных элементов.
Теперь собираем вместе доказанные факты и получаем требуемый результат.
\end{proof}

Заметим, что таким образом мы можем считать определитель для блочно верхнетреугольных матриц и для блочно нижнетреугольных матриц с любым количеством блоков.
Формулы тогда будут выглядеть так
\[
\det
\begin{pmatrix}
{A_1}&{*}&{\ldots}&{*}\\
{}&{A_2}&{\ldots}&{*}\\
{}&{}&{\ddots}&{\vdots}\\
{}&{}&{}&{A_k}\\
\end{pmatrix}
=
\det
\begin{pmatrix}
{A_1}&{}&{}&{}\\
{*}&{A_2}&{}&{}\\
{\vdots}&{\vdots}&{\ddots}&{}\\
{*}&{*}&{\ldots}&{A_k}\\
\end{pmatrix}
=\det A_1 \ldots \det A_k
\]
где $A_i\in\Matrix{n_i}$ -- обязательно квадратные матрицы.
Это правило является обобщением утверждения о вычислении определителя для треугольных матриц.

\subsection{Мультипликативные отображения}

Давайте подытожим, что мы показали.
Утверждение~\ref{claim::DetPolyAnti} вместе с утверждением~\ref{claim::DetTranspose} объясняют почему определитель является полилинейной кососимметрической функцией как строк, так и столбцов.
Далее утверждение~\ref{claim::PolyAntiUnique} доказывает, что любая полилинейная кососимметричная функция по строкам, принимающая значение $1$ на единичной матрице, должна быть определителем.
С помощью утверждения~\ref{claim::DetTranspose} мы получаем аналогичный результат для столбцов.
Таким образом мы показали эквивалентность подхода (III) подходам (II) и (II').

Теперь, утверждение~\ref{claim::DetMulti} показывает, что определитель обязательно мультипликативен, а свойство (I)~(2) следует из явных вычислений для элементарных матриц.
Тем самым мы показали, что (II) и (III) влекут (I).
Осталось показать, что (I) влечет (III), т.е. что определитель является единственной функцией с такими свойствами.

\begin{claim}
\label{claim::DetMultiUnique}
Пусть $\psi\colon \Matrix{n}\to \mathbb R$ -- отображение удовлетворяющее свойствам:
\begin{enumerate}
\item $\psi(AB) = \psi(A)\psi(B)$ для любых $A,B\in\Matrix{n}$.

\item 
$
\psi
\begin{pmatrix}
{1}&{}&{}&{}\\
{}&{\ddots}&{}&{}\\
{}&{}&{1}&{}\\
{}&{}&{}&{d}\\
\end{pmatrix}
= 
d
$ для любого ненулевого $d\in\mathbb R$.
\end{enumerate}
Тогда $\psi = \det$.
\end{claim}

Доказательство этого утверждения разобьем в несколько этапов.
В начале докажем элементарные свойства мультипликативных отображений.

\begin{claim}
Пусть $\psi\colon \Matrix{n}\to \mathbb R$ отображение со свойством $\psi(AB) = \psi(A)\psi(B)$ для всех $A,B\in\Matrix{n}$.
Тогда
\begin{enumerate}
\item Если $P\in \Matrix{n}$ такая что $P^2 = P$, то $\psi(P)$ равно либо $0$ либо $1$.

\item В частности, значение $\psi(0)$ и $\psi(E)$ равно либо $0$ либо $1$.

\item Если $\psi(E) = 0$, то $\psi(A) = 0$ для любой матрицы $A\in\Matrix{n}$.

\item Если $\psi(E) = 1$, то $\psi(A^{-1}) = \psi(A)^{-1}$ для любой обратимой матрицы $A\in\Matrix{n}$.
\end{enumerate}
\end{claim}
\begin{proof}

(1) Применим $\psi$ к тождеству $P^2 = P$, получим $\psi(P) = \psi(P P) = \psi(P)\psi(P)$.
То есть число $\psi(P)$ в квадрате равно самому себе.
Значит либо $\psi(P) = 0$, либо $\psi(P) = 1$.

(2) Заметим, что $E^2 = E$ и $0^2 = 0$ и воспользуемся предыдущим пунктом.

(3) Применим $\psi$ к тождеству $A = A E$, получим $\psi(A) = \psi(A)\psi(E) = 0$.

(4) Применим $\psi$ к тождеству $A A^{-1} = E$, получим $1 = \psi(E) = \psi(AA^{-1})=\psi(A)\psi(A^{-1})$.
Значит число $\psi(A^{-1})$ является обратным к числу $\psi(A)$, что и требовалось показать.
\end{proof}

\begin{claim}
\label{claim::MultiOnElementary}
Пусть $\psi\colon \Matrix{n}\to \mathbb R$ -- отображение удовлетворяющее свойствам:
\begin{enumerate}
\item $\psi(AB) = \psi(A)\psi(B)$ для любых $A,B\in\Matrix{n}$.

\item $\psi(D_n(\lambda)) = \lambda$ для любого ненулевого $\lambda\in\mathbb R$.
\end{enumerate}
Тогда
\begin{enumerate}
\item $\psi(S_{ij}(\lambda)) = 1 = \det(S_{ij}(\lambda))$.

\item $\psi(U_{ij}) = -1 = \det(U_{ij})$.

\item $\psi(D_i(\lambda)) = \lambda = \det(D_i(\lambda))$.
\end{enumerate}
\end{claim}
\begin{proof}
В начале заметим, что $\psi(E) = 1$.
Потому что иначе $\psi(A) = 0$ для любой матрицы, что противоречит второму свойству.
А раз $\psi(E)=1$, то можно пользоваться пунктом~(4) предыдущего утверждения.

(1) Для доказательства воспользуемся следующим замечанием: если $A,B\in\Matrix{n}$ -- произвольные обратимые матрицы, то $\psi(ABA^{-1}B^{-1}) = 1$.
Действительно, 
\[
\psi(ABA^{-1}B^{-1}) = \psi(A)\psi(B)\psi(A)^{-1}\psi(B)^{-1}=\psi(A)\psi(A)^{-1}\psi(B)\psi(B)^{-1} = 1
\]
Для доказательства нам достаточно представить $S_{ij}(\lambda)$ в таком виде.
Давайте проверим, что 
\[
S_{ij}(\lambda) = D_i(2) S_{ij}(\lambda)D_i^{-1}(2)S_{ij}(\lambda)^{-1}
\]
Это равенство проверяется непосредственно глядя на матрицы.
Давайте для простоты проверим в случае $2$ на $2$, когда все наглядно:
\[
\begin{pmatrix}
{2}&{0}\\
{0}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{1}&{\lambda}\\
{0}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{\frac{1}{2}}&{0}\\
{0}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{1}&{-\lambda}\\
{0}&{1}\\
\end{pmatrix}
=
\begin{pmatrix}
{1}&{2\lambda}\\
{0}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{1}&{-\lambda}\\
{0}&{1}\\
\end{pmatrix}
=
\begin{pmatrix}
{1}&{\lambda}\\
{0}&{1}\\
\end{pmatrix}
\]

(3) Для доказательства этого пункта воспользуемся следующим наблюдением: если $A,B\in\Matrix{n}$ причем $A$ обратима, тогда $\psi(ABA^{-1}) = \psi(B)$.
Действительно, 
\[
\psi(ABA^{-1}) = \psi(A)\psi(B)\psi(A)^{-1} =  \psi(B)\psi(A)\psi(A)^{-1} = \psi(B)
\]
Мы уже знаем, что $\psi(D_n(\lambda)) = \lambda$ по условию.
Надо лишь доказать, что для всех $i$ выполнено $\psi(D_i(\lambda)) = \lambda$.
Для этого достаточно представить $D_{i}(\lambda) = A D_{i+1}(\lambda)A^{-1}$.
Возьмем в качестве $A = U_{i, i+1}$ элементарную матрицу переставляющую $i$ и $i+1$ строки.
Тогда $A^{-1} = A$.
Более того, легко видеть, что $D_{i}(\lambda) = U_{i, i+1} D_{i+1}(\lambda)U_{i, i+1}^{-1}$.
Действительно, умножение на $U_{i, i+1}$ слева -- переставляет $i$ и $j$ строки, а умножение на $U_{i, i+1}$ справа равносильно умножению на $U_{i, i+1}^{-1}$ и оно переставляет $i$ и $j$ столбцы.
Для наглядности двумерный случай:
\[
\begin{pmatrix}
{0}&{1}\\
{1}&{0}\\
\end{pmatrix}
\begin{pmatrix}
{1}&{0}\\
{0}&{\lambda}\\
\end{pmatrix}
\begin{pmatrix}
{0}&{1}\\
{1}&{0}\\
\end{pmatrix}
=
\begin{pmatrix}
{\lambda}&{0}\\
{0}&{1}\\
\end{pmatrix}
\]

(2) Здесь мы воспользуемся тем, что элементарные преобразования второго типа можно выразить через элементарные преобразования первого и третьего типа, а именно, давайте проверим, что 
\[
U_{ij} = D_i(-1)S_{ji}(1)S_{ij}(-1)S_{ji}(1)
\]
Применив $\psi$ к этому равенству и воспользовавшись предыдущими двумя пунктами, мы получаем требуемое.
Однако, остается законный вопрос: а как вообще можно догадаться до такого и проверить?
Вот вам рассуждение приводящее к такому ответу.
Давайте последовательно применять элементарные преобразования первого и третьего типа к единичной матрице, пока не получим из нее матрицу $U_{ij}$.
Написанное равенство означает, что надо сделать так: (1) прибавить $i$ строку к $j$, (2) вычесть $j$ строку из $i$, (3) прибавить $i$ строку к $j$, (4) умножить $i$ строку на $-1$.
Давайте для наглядности это проделаем на матрицах $2$ на $2$.
Ниже мы последовательно умножаем матрицу с левой стороны на матрицу написанную над стрелкой:
\[
\xymatrix@R=10pt@C=40pt{
 	{
 	\begin{pmatrix}
	{1}&{0}\\
	{0}&{1}\\
	\end{pmatrix}
	}\ar[r]^-{
	\begin{pmatrix}
	{1}&{0}\\{1}&{1}\\
	\end{pmatrix}
	}&{
 	\begin{pmatrix}
	{1}&{0}\\
	{1}&{1}\\
	\end{pmatrix}
	}\ar[r]^-{
 	\begin{pmatrix}
	{1}&{-1}\\
	{0}&{1}\\
	\end{pmatrix}
	}&{
 	\begin{pmatrix}
	{0}&{-1}\\
	{1}&{1}\\
	\end{pmatrix}
	}\ar[r]^{
 	\begin{pmatrix}
	{1}&{0}\\
	{1}&{1}\\
	\end{pmatrix}
	}&{
 	\begin{pmatrix}
	{0}&{-1}\\
	{1}&{0}\\
	\end{pmatrix}
	}\ar[r]^{
 	\begin{pmatrix}
	{-1}&{0}\\
	{0}&{1}\\
	\end{pmatrix}
	}&{
 	\begin{pmatrix}
	{0}&{1}\\
	{1}&{0}\\
	\end{pmatrix}
	}
}
\]
\end{proof}


%% Переписать с учетом предложения на лекции
\begin{claim}
\label{claim::MultiOnIdempotent}
Пусть $\psi\colon \Matrix{n}\to \mathbb R$ -- отображение удовлетворяющее свойствам:
\begin{enumerate}
\item $\psi(AB) = \psi(A)\psi(B)$ для любых $A,B\in\Matrix{n}$.

\item $\psi(D_n(\lambda)) = \lambda$ для любого ненулевого $\lambda\in\mathbb R$.
\end{enumerate}
И пусть $P_k\in\Matrix{n}$ -- диагональная матрица, у которой $k$ единиц на диагонали и $n-k$ нулей, причем $k< n$.
Тогда $\psi(P_k) = 0$.
\end{claim}
\begin{proof}
Я приведу два доказательства.
Первое будет супер коротким, а второе будет годиться в более общей ситуации.%
\footnote{Имеется в виду случай матриц над произвольным полем, если вы знаете, что это такое.
Позже мы с этим познакомимся.}

\noindent\textbf{Доказательство I.} Заметим, что $D_n(\lambda) P_k = P_k$ при $k < n$ и любом ненулевом $\lambda \in \mathbb R$.
Применим к этому равенству $\psi$ и получим
\[
\lambda \psi(P_k) = \psi(D_n(\lambda)) \psi(P_k) = \psi(P_k)
\]
Выберем любое ненулевое число $\lambda$ отличное от $1$, тогда получим, что $\psi(P_k)$ обязано быть нулем.%
\footnote{Для тех, кто уже знает о том, что бывают разные поля.
Обратите внимание, что это доказательство не работает, если в поле нет элементов кроме $0$ и $1$, то есть в случае $\mathbb Z_2$.
Однако, есть куда более}


\noindent\textbf{Доказательство II.} В начале покажем, что $\psi(0) = 0$.
Мы уже знаем, что $\psi(0)$ либо $0$ либо $1$.
Предположим, что $\psi(0)=1$.
Применим $\psi$ к тождеству $0 = A 0$, получим $\psi(0) = \psi(A)\psi(0)$.
А следовательно $\psi(A) = 1$ для любого $A\in\Matrix{n}$, что противоречит второму свойству.

Теперь докажем, что $\psi(P_k) = 0$.
Заметим, что $P_k^2 = P_k$.
Значит $\psi(P_k)$ либо $0$, либо $1$.
Давайте предположим, что $\psi(P_k) = 1$.
Теперь покажем, что из равенства $\psi(P_k) = 1$ следует равенство $\psi(P_{k-1}) = 1$ для любого $k < n$.
Если это так, то применив это соображение $k$ раз, мы получим $\psi(P_0) = 1$, но $P_0 = 0$, а $\psi(0) = 0$.

Теперь мы боремся за то, чтобы из равенства $\psi(P_k) = 1$ вывести равенство $\psi(P_{k-1}) = 1$ для любого $k < n$.
Рассмотрим следующие матрицы%
\footnote{Здесь $U_{k, k+1}$ -- матрица перестановки $k$ и $k+1$ строк.
Именно в этом месте мы пользуемся тем, что $k<n$.}
\[
P_k=
\begin{pmatrix}
{1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{1}&{}&{}&{}\\
{}&{}&{}&{1}&{}&{}\\
{}&{}&{}&{}&{0}&{}\\
{}&{}&{}&{}&{}&{\ddots}\\
\end{pmatrix}
\quad\text{и}\quad
U_{k,k+1}P_kU_{k,k+1}^{-1}=
\begin{pmatrix}
{1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{1}&{}&{}&{}\\
{}&{}&{}&{0}&{}&{}\\
{}&{}&{}&{}&{1}&{}\\
{}&{}&{}&{}&{}&{\ddots}\\
\end{pmatrix}
\]
Тогда ясно, что $P_{k-1} = P_k U_{k,k+1}P_k U_{k,k+1}^{-1}$.
А значит, если мы применим $\psi$ к последнему равенству, то получим
\[
\psi(P_{k-1}) = \psi(P_k)\psi(U_{k,k+1})\psi(P_k)\psi(U_{k,k+1}^{-1}) = \psi(P_k)^2 = 1
\]
Что и требовалось.
\end{proof}


\begin{proof}
[Доказательство Утверждения~\ref{claim::DetMultiUnique}]
В начале пусть $A\in\Matrix{n}$ -- невырожденная матрица.
Тогда мы знаем, что она является произведением элементарных матриц $A = U_1\ldots U_k$.
Применим $\psi$ к этому равенству, получим $\psi(A) = \psi(U_1)\ldots \psi(U_k)$.
С другой стороны по утверждению~\ref{claim::MultiOnElementary} получаем $\psi(A) = \det(U_1)\ldots \det(U_k)$.
А из мультипликативности определителя, следует, что правая часть равна $\det A$.

Теперь покажем, что $\psi$ совпадает с $\det$ на всех матрицах.
Пусть $A\in\Matrix{n}$ -- произвольная матрица.
Тогда элементарными преобразованиями строк она приводится к ступенчатому виду, то есть $A$ можно представить в виде $TB$, где $T$ -- обратимая, а $B$ имеет улучшенный ступенчатый вид.
После этого к $B$ можно применить элементарные преобразования столбцов и привести к виду $P_k$.
То есть $B$ представляется в виде $P_k D$, где $D$ -- обратимая матрица.%
\footnote{Обратите внимание, что $k$ -- наш старый знакомый, а именно -- количество главных переменных в системе $Ax = 0$.} То есть любая матрица $A$ представляется в виде $A = T P_k D$, где $T,D\in\Matrix{n}$ -- обратимые матрицы.
Тогда, применим к этому равенству $\psi$, получим
\[
\psi(A) = \psi(T)\psi(P_k)\psi(D) = 0
\]
Последнее равенство в силу $\psi(P_k) = 0$ из утверждения~\ref{claim::MultiOnIdempotent}.
В свою очередь, так как $A$ необратима, то $\det(A) = 0$ тоже.
\end{proof}


